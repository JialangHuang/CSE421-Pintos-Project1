            +--------------------+
            |        CS 140      |
            | PROJECT 1: THREADS |
            |   DESIGN DOCUMENT  |
            +--------------------+
                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Jialang Huang <jialangh@buffalo.edu>
JinKyu Hwang<jinkyuhw@buffalo.edu>
Jason Pettrone <japettro@buffalo.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
in thread
struct thread {
           Int64_t wake_tick;  //this is a variable to indicate when the thread is woken up.
}
 
in timer.c
 
struct list waiting_queue;  // this is a collection of sleeping thread. When timer_sleep is called, the current thread goes to this collection


---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.
    After timer_sleep function is called, it will save wake_tick and initialize a semaphore(sem_init). Finally the current thread goes to a waiting_queue by wake_tick (by ascending order). And we use sema_down() and sema_up() to make the thread sleep and wake up.


>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?
    The waiting_queue is sorted in ascending order of ticks, we can access the soonest thread by popping the front of the queue. Therefore, we can handle the thread and call sema_up() for it to be woken up.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?
    We have a semaphore to control this situation. Even though multiple threads call the function simultaneously, the semaphore will control this.


>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?
    As stated above, the semaphore can also control this situation.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
    We can easily pop the next thread in the waiting queue by sorting them in ascending order via ticks. We can also avoid the situation where multiple threads call the timer_sleep function simultaneously by using a semaphore. 


             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
In thread.h 
thread{
Int origi_priority: to store the origin priority when the current thread donate by other thread
Struct lock waiting_lock: the lock which current thread are waiting 
Struct list donations_list:  this is a list of other thread which waiting on locks the current thread has

}
>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)



------------------     ----------------    -----------------         
l Thread A     |    | Thread B  l    | Thread C   |    
| Priority : 8   |    | Priority : 9 |    |Priority : 10  |
| Held L  :  X  |    |                  |    |Lock      : X |
------------------     ----------------     -----------------     

Since the first thread A is created and there is no other threads in the queue, A gets the processor immediately and create lock X. Then thread B is created and also has a higher priority, B can access to the processor. Finally thread C is created and has highest priority, C gets to the processor. But C needs to acquire lock X, here priority donation comes to play.  To acquire lock X, operating system increases A’s priority temporarily to match with priority of thread C. So B now acquires the lock and after B finish the process, the thread B with next higher priority gets the processor eventually and A will finish itself finally. 



---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
    The highest priority thread is placed at the front of the list

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
If the lock_holder is NULL, the lock_holder = current thread
If the lock_holder is not NULL, the current thread->waiting_lock = current lock
    Then check the lock_holder priority:
        If lock_holder priority greater than current thread priority: return
        If lock_holder priority less than current thread priority:
         Add current thread to lock holder donations_list 
                                             Lock_donate_priority() use this function to donate the priority to the                  thread 
In lock_donate_priority(), if the current  lock holder has another waiting_lock, donate the current thread priority to next thread until the thread doesn’t have a waiting_lock   
>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
    When lock_release() call, check if any thread is waiting for the lock, if true, remove them from the current thread donations_list and restore current thread origin priority.
---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

It’s possible that we try to set the priority of the thread with thread_set_priority() but then midway through we get donated a new priority from another thread. This results in situations where we can end either with the donated priority or the priority we set. The current solution is to disable interrupts but there may be a way to do this with a lock.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

By keeping the priority list ordered, retrieval is very quick, as we can just pop the head of the list to get the thread with the highest priority. This is especially useful in the lock_release() method.

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In thread.h
Struct thread 
{
    int nice_value;
    Int recent_cpu;  
}
In thread.c
    Int load_avg;

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority         thread
ticks   A    B    C      A   B   C      to run
-----    --    --    --      --   --    --      ------
 0       0    1     2      63  61  59       A
 4       4    1     2      62  61  59       A
 8       8    1     2      61  61  59       B      
12      8    5     2      61  60  59       A
16      12  5     2      60  60  59       B
20      12  9     2      60  59  59       A
24      16   9     2      59  59  59      C
28      16   9     6      59  59  58      B
32      16   13   6      59  58  58      A
36      20   13   6      58  58  58      C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

One ambiguity is when two threads have the same priority. Typically this would be resolved in a round-robin or FCFS fashion, but we want to make sure that the thread that has not run recently is prioritized to run next. At timer tick 8 in the chart above we can see this ambiguity. Both A and B are the same priority, yet we choose B to run since it hasn’t been run for a longer period of time.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

The more code that is inside interrupt context, the worse the performance due to less concurrency. The goal is to put as little code in interrupt context as possible in order to increase concurrency and therefore increase performance.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

We haven’t fully fleshed out the design on this part yet, but we are going to be using 64 queues for each priority level as suggested in lecture. We are going to use the running averages of recent_cpu and load_avg in order to increase the efficiency of the scheduling. One downside I can see is that we are currently trying to track how long a thread hasn’t been able to run and then using that value to determine what thread runs if they both have the same (and highest) priority. Searching for that thread is an O(n) operation and could slow down our scheduling algorithm. This is something that is subject to change.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

We are going to write a fixed-point.h header file with functions to perform the necessary operations as suggested in lecture 5.

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?


